{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pipeline.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOxkZhwHAwpy9IVm/w7qCVZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ggarciabas/ml_engineer/blob/dspipe/pipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pipeline Fraude\n",
        "\n",
        "- [sklearn pipes](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html)"
      ],
      "metadata": {
        "id": "wsquQu6oiOyg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import Pipeline"
      ],
      "metadata": {
        "id": "sf74keaSihfL"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Leitura dos dados e isolamento (treino, teste e validação)"
      ],
      "metadata": {
        "id": "IX-g-lhGjsDh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Funções"
      ],
      "metadata": {
        "id": "9xTBpNNCj7nZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_fraudes_data (pdM, start=None, end=None)->tuple:\n",
        "  pdf = pdM.copy()\n",
        "  if start != None:\n",
        "    pdf = pdf[(pdf['fecha_d']>=start)&(pdf['fecha_d']<=end)]\n",
        "  pdf = pdf[['fecha_d', 'fraude','a']].groupby(['fecha_d', 'fraude']).count().reset_index()\n",
        "  pdf = pdf.pivot(index=\"fecha_d\", columns=[\"fraude\"], values=\"a\")\n",
        "  print (f\"Fraude {pdf[1].mean()} avg.\\tGenuine: {pdf[0].mean()} avg.\")\n",
        "  pdf.plot()\n",
        "  return pdf[1].sum(),pdf[0].sum()"
      ],
      "metadata": {
        "id": "GQXilsqXj7Iq"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Leitura dos dados"
      ],
      "metadata": {
        "id": "5mgwWBzHkWTP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "# Cria Dataframe inicial\n",
        "url='https://drive.google.com/file/d/1dRDvoSOtdtsgOG65UVKLTBlzejg_cX4P/view?usp=sharing' \n",
        "url2='https://drive.google.com/uc?export=download&id=' + url.split('/')[-2]\n",
        "# https://stackoverflow.com/questions/56611698/pandas-how-to-read-csv-file-from-google-drive-public\n",
        "pd_dados = pd.read_csv(url2)"
      ],
      "metadata": {
        "id": "BKoPbV46kI7J"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filtra data sem hora\n",
        "pd_dados['fecha_d'] = pd_dados['fecha'].apply(lambda x: x[:10])"
      ],
      "metadata": {
        "id": "GUo3KFGskUs8"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd_dados['fecha'] = pd.to_datetime(pd_dados['fecha'])\n",
        "pd_dados['fecha_d'] = pd.to_datetime(pd_dados['fecha_d'])"
      ],
      "metadata": {
        "id": "l5DO9b0dm6H1"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Feature store\n",
        "\n",
        "Conhecimento de risco para categoria do produto e país.\n",
        "\n",
        "Informação que precisa ser conhecida de tempos em tempos."
      ],
      "metadata": {
        "id": "I0WdQuIV0LtX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "def calc_risk (pdf, feat, delay=7, janelas=[1,7]):\n",
        "    \"\"\"\n",
        "      Calcula o risco de fraude para feature\n",
        "      pdf: dataframe com filtro feature a ser avaliada\n",
        "      delay: prazo de identificação da fraude\n",
        "      janelas: janelas de análise, como temos poucos dados faremos de 1 em 1 dia e de 7 em 7\n",
        "    \"\"\"\n",
        "    pdf = pdf.sort_values('fecha_d')\n",
        "    pdf = pdf.set_index('fecha_d')\n",
        "    # quantidade de transações fraudulentas + contagem de transações --> no período de delay \n",
        "    fraudes = pdf['fraude'].rolling(f'{delay}d').sum()\n",
        "    trxS = pdf['fraude'].rolling(f'{delay}d').count()\n",
        "    for janela in janelas:\n",
        "      fraudeJ = pdf['fraude'].rolling(f'{delay+janela}d').sum() \n",
        "      trxJ = pdf['fraude'].rolling(f'{delay+janela}d').count() \n",
        "      riskJ=(fraudeJ-fraudes)/(trxJ-trxS)\n",
        "      riskJ = [0 if math.isnan(x) else x for x in riskJ]\n",
        "      pdf[f'{feat}_trx_{janela}'] = list((trxJ-trxS))\n",
        "      pdf[f'{feat}_risk_{janela}'] = list(riskJ)\n",
        "    pdf = pdf.reset_index()\n",
        "    return pdf"
      ],
      "metadata": {
        "id": "668S0BOi0Kk5"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_store = pd_dados.copy()"
      ],
      "metadata": {
        "id": "dR-8Ulsc0rK1"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_store = feature_store.groupby('j').apply(lambda x: calc_risk(x, 'j')).sort_values('fecha_d').reset_index(drop=True)"
      ],
      "metadata": {
        "id": "4se0fyB20mAL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_store = feature_store.groupby('g').apply(lambda x: calc_risk(x, 'g')).sort_values('fecha_d').reset_index(drop=True)"
      ],
      "metadata": {
        "id": "SNIkg35O0pJK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_store[['fecha_d', 'g', 'g_trx_1', 'g_risk_1', 'g_trx_7', 'g_risk_7']].to_csv('feature_store_g.csv')"
      ],
      "metadata": {
        "id": "FzCB-UI61YrL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_store[['fecha_d', 'j', 'j_trx_1', 'j_risk_1', 'j_trx_7', 'j_risk_7']].to_csv('feature_store_j.csv')"
      ],
      "metadata": {
        "id": "quLA2oVM4OwP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Divide dados\n",
        "\n",
        "- Treino: `2020-03-22` até `2020-03-28`\n",
        "- Delay: `2020-03-29` até `2020-04-04`\n",
        "- Teste: `2020-04-05` até `2020-04-11`"
      ],
      "metadata": {
        "id": "h_DO58q6kFQN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Treino\n",
        "dataTrain1 = {'start':'2020-03-22', 'end':'2020-03-28'}\n",
        "pdfTrain1 = pd_dados.copy()\n",
        "pdfTrain1 = pdfTrain1[(pdfTrain1['fecha_d']>=dataTrain1['start'])\n",
        "                      &(pdfTrain1['fecha_d']<=dataTrain1['end'])]\n",
        "print (pdfTrain1.shape)\n",
        "fraude,genuine = plot_fraudes_data(pd_dados, dataTrain1['start'], dataTrain1['end'])\n",
        "print (f\"Fraude: {fraude} ({fraude/pdfTrain1.shape[0]})\\tGenuine: {genuine} ({genuine/pdfTrain1.shape[0]})\")"
      ],
      "metadata": {
        "id": "1h8fpLM1jrb1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Delay\n",
        "dataDelay1 = {'start':'2020-03-29', 'end':'2020-04-04'}\n",
        "plot_fraudes_data(pd_dados, dataDelay1['start'], dataDelay1['end'])"
      ],
      "metadata": {
        "id": "reDlcxZ6j2Tf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Teste\n",
        "dataTest1 = {'start':'2020-04-05', 'end':'2020-04-11'}\n",
        "pdfTest1 = pd_dados.copy()\n",
        "pdfTest1 = pdfTest1[(pdfTest1['fecha_d']>=dataTest1['start'])\n",
        "                      &(pdfTest1['fecha_d']<=dataTest1['end'])]\n",
        "print (pdfTest1.shape)\n",
        "fraude,genuine = plot_fraudes_data(pd_dados, dataTest1['start'], dataTest1['end'])\n",
        "print (f\"Fraude: {fraude} ({fraude/pdfTest1.shape[0]})\\tGenuine: {genuine} ({genuine/pdfTest1.shape[0]})\")"
      ],
      "metadata": {
        "id": "LfW_nHoTj0iy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Classes"
      ],
      "metadata": {
        "id": "5Gw1jaZGiU-f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.base import BaseEstimator, TransformerMixin"
      ],
      "metadata": {
        "id": "MMr0RHfhmIbN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Transformer para Risco de classes\n",
        "import math\n",
        "class RiskTransformer(BaseEstimator, TransformerMixin):\n",
        "  \"\"\"\n",
        "    Calcula do risco para feature consultando na feature store\n",
        "  \"\"\"\n",
        "  def __init__(self, feature_name, feat_store):\n",
        "    self.feature_name = feature_name\n",
        "    self.feat_store = feat_store\n",
        "\n",
        "  def fit(self, X, y = None):\n",
        "    return self\n",
        "\n",
        "  def transform(self, X, y = None):    \n",
        "    X_ = X.copy()\n",
        "    X_ = X_.merge(self.feat_store, on=['fecha_d', self.feature_name], how='left')\n",
        "    return X_"
      ],
      "metadata": {
        "id": "MvifD6VamA2_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transformer para identificar final de semana\n",
        "class IsWeekendTransformer(BaseEstimator, TransformerMixin):\n",
        "  \"\"\"\n",
        "    Identifica se a operação ocorreu no final de semana\n",
        "  \"\"\"\n",
        "  def __init__(self, feature_date):\n",
        "    self.feature_date = feature_date\n",
        "\n",
        "  def fit(self, X, y = None):\n",
        "    return self\n",
        "\n",
        "  def transform(self, X, y = None):    \n",
        "    X_ = X.copy()\n",
        "    X_ = X_[self.feature_date].apply(lambda x: 1 if x.weekday()>=5 else 0)\n",
        "    return X_"
      ],
      "metadata": {
        "id": "Z5NXMSGW9mfx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Versão tratamento manual"
      ],
      "metadata": {
        "id": "VOSh8yTjiy7p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Carrega a feature store\n",
        "feat_store = pd.read_csv('feature_store.csv')"
      ],
      "metadata": {
        "id": "Rui8rDlZ_gZV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Features manual\n",
        "# feat = ['a', 'b', 'c', 'd', 'e', 'f', 'h', 'k', 'l',\n",
        "#         'm', 'n',  'monto', 'weekend', 'night', 'cat_trx_1', 'cat_risk_1', 'cat_trx_7',\n",
        "#         'cat_risk_7', 'pais_trx_1', 'pais_risk_1', 'pais_trx_7', 'pais_risk_7',\n",
        "#         'miss_o', 'is_p']\n",
        "target = 'fecha'\n",
        "# cols = feat+[target]+['fecha_d']"
      ],
      "metadata": {
        "id": "KpUFXfcb8RAz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JYntx7nug8M9"
      },
      "outputs": [],
      "source": [
        "p_manual = Pipeline([('risk_g', RiskTransformer(feature_name='g', feat_store=feat_store)), \n",
        "                      ('risk_j', RiskTransformer(feature_name='j', feat_store=feat_store))\n",
        "                    ])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "p_manual.fit(pdfTrain1, pdfTrain1[target])\n",
        "#p_manual.score(X_test, y_test)"
      ],
      "metadata": {
        "id": "uc1PB_Usi7ib"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output = p_manual.transform(pdfTrain1)"
      ],
      "metadata": {
        "id": "M1O4i_Ww9b2q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output"
      ],
      "metadata": {
        "id": "0ddq3_to9jE_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "XgZI3Li0_xbJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}